# -*- coding: utf-8 -*-
"""LearnCraft_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16-fdjOOmmyNZcQ97wJZ9qlW-R8ffbj-_
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import sklearn.neighbors
from generateData import generate_n_images

class KNNClassifier:

    def __init__(self, k=5):
        """
        Initialize our custom KNN classifier
        :param k: the number of nearest neighbors to consider for classification
        """
        self._k = k
        self._ball_tree = None
        self._y = None
        self.label_to_index = None
        self.index_to_label = None

    def fit(self, X, y):
        """
        Fit the model using the provided data
        :param X: 2-D np.array of shape (number training samples, number of features)
        :param y: 1-D np.array of shape (number training samples,)
        :return: self
        """
        self._ball_tree = sklearn.neighbors.BallTree(X)  # See documentation of BallTree and how it's used
        print("0")
        self._y = y
        # Should be used to map the classes to {0,1,..C-1} if needed (C is the number of classes)
        # We can assume that the training data contains samples from all the possible classes
        classes = np.unique(y)
        print("1")
        self.label_to_index = dict(zip(classes, range(classes.shape[0])))
        print("2")
        self.index_to_label = dict(zip(range(classes.shape[0]), classes))
        print("3")
        return self

    def majority_vote(self, indices_nearest_k, distances_nearest_k=None):
        """
        Given indices of the nearest k neighbors for each point, report the majority label of those points.
        :param indices_nearest_k: np.array containing the indices of training neighbors, of shape (M, k)
        :param distances_nearest_k: np.array containing the corresponding distances of training neighbors, of shape (M, k)
        :return: The majority label for each row of indices, shape (M,)
        """

        # Workspace 1.1

        #BEGIN 
        voted_labels = np.empty(indices_nearest_k.shape[0])
        
        #print("indices nearest k:", indices_nearest_k)
        # code here
        classes = np.unique(self._y)
        i = 0
        for M in indices_nearest_k:
            labelcounts = dict(zip(classes, np.zeros(len(classes))))
            #print(distances)
            maxkey = 0
            label = 0
            tie = False
            for k in M:
                labelcounts[self._y[k]] += 1
            #print(labelcounts)
            for key in labelcounts:
                if labelcounts[key] > maxkey:
                    maxkey = labelcounts[key]
                    label = key
                if labelcounts[key] == maxkey:
                    tie = True
            if tie:
                M = M[0:-1]
                for k in M:
                    labelcounts[self._y[k]] += 1
                for key in labelcounts:
                    if labelcounts[key] > maxkey:
                        maxkey = labelcounts[key]
                        label = key
            voted_labels[i] = label
            i = i + 1
        #END
        #print("voted labels ", voted_labels)
        return voted_labels

   

    def getshape(imageMat, return_colors = False, f = None, sensitivity = None):
      '''
      inputs an image and extracts the pixels that aren't grey
      returns: array of x values and array of y values for the pixels, (and the color of those pixels)
      '''
      def stone(color,sensitivity):
        '''
        currently a dumb model to calculate if the color is grey
        '''
        r,g,b, = 255*color[:3]
        if (abs(g-r) > sensitivity or
            abs(g-b) > sensitivity or
            abs(r-b) > sensitivity ):
            return False
        else:
            return True
      if f == None:
          f = lambda x: stone(color, 0 if sensitivity == None else sensitivity)
      X = [[],[]]
      if(return_colors):
          colors = []
      for y, xmatr in enumerate(imageMat):
          for x, color in enumerate(xmatr):
              if not f(color):
                  X[0].append(x)
                  X[1].append(y)
                  if(return_colors):
                      colors.append(color)
      if return_colors:
          return X, colors 
      else:
          return X
        
    def predict(self, X):
        """
        Given new data points, classify them according to the training data provided in fit and number of neighbors k
        You should use BallTree to get the distances and indices of the nearest k neighbors
        :param X: feature vectors (num_points, num_features)
        :return: 1-D np.array of predicted classes of shape (num_points,)
        """
        # Workspace 1.2
        #BEGIN 
        # code here
        #print(X)
        #X = getshape(X)
        distances_nearest_k, indices_nearest_k = self._ball_tree.query(X, self._k)
        '''
        # get the (x,y) coordinates of the pixels of interest
        x, y = get_shape( input image )

        # center the shape onto some universal reference point
        x_centered, y_centered = center(x, y)

        prediction from shape = KNN(x_centered, y_centered)

        if( can't predict from shape ):
            # try some rotations or something 
        else:
            get location info from x and y
        return prediction_from_shape and location info 
        '''
        #END
        return self.majority_vote(indices_nearest_k, distances_nearest_k)

    def confusion_matrix(self, X, y):
        """
        Generate the confusion matrix for the given data
        :param X: an np.array of feature vectors of points, shape (N, n_features)
        :param y: the corresponding correct classes of our set, shape (N,)
        :return: a C*C np.array of counts, where C is the number of classes in our training data
        """
        # The rows of the confusion matrix correspond to the counts from the true labels, the columns to the predictions'
        # Workspace 1.3
        c_matrix = np.zeros((len(self.label_to_index), len(self.label_to_index)))
        #BEGIN 
        # code here
        prediction = self.predict(X)
        #print("y= ",y)
        #print("X= ",X)
        for i in range(len(y)):
            #print("labeltoindex of pred = ",self.label_to_index[prediction[i]])
            #print(self.label_to_index)
            c_matrix[self.label_to_index[y[i]]][self.label_to_index[prediction[i]]] += 1
        #END
        return c_matrix

    def accuracy(self, X, y):
      """
      Return the accuracy of the classifier on the data (X_test, y_test)
      :param X: np.array of shape (m, number_features)
      :param y: np.array of shape (m,)
      :return: accuracy score [float in (0,1)]
      """
      # Workspace 1.4

      #BEGIN 
      # code here
      cmat = self.confusion_matrix(X,y)
      score = np.trace(cmat)/len(y)
      #END
      return score

"""add a rotation part to the generate data python"""




